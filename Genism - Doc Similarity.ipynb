{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand Genism for Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 6\n"
     ]
    }
   ],
   "source": [
    "doc = [\"She was worried about her examinations\",\n",
    "        \"He was anxious about his interview\",\n",
    "        \"He faught against the enemies\",\n",
    "         \"She fights alot\",\n",
    "          \"Mango and apple are my favorite fruits\",\"I hate pumpkin and papaya\"]\n",
    "print(\"Number of documents:\",len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['she', 'was', 'worried', 'about', 'her', 'examinations'], ['he', 'was', 'anxious', 'about', 'his', 'interview'], ['he', 'faught', 'against', 'the', 'enemies'], ['she', 'fights', 'alot'], ['mango', 'and', 'apple', 'are', 'my', 'favorite', 'fruits'], ['i', 'hate', 'pumpkin', 'and', 'papaya']]\n"
     ]
    }
   ],
   "source": [
    "gen_docs = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in doc]\n",
    "print(gen_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(27 unique tokens: ['about', 'examinations', 'her', 'she', 'was']...)\n",
      "3\n",
      "Number of words in dictionary: 27\n",
      "0 about\n",
      "1 examinations\n",
      "2 her\n",
      "3 she\n",
      "4 was\n",
      "5 worried\n",
      "6 anxious\n",
      "7 he\n",
      "8 his\n",
      "9 interview\n",
      "10 against\n",
      "11 enemies\n",
      "12 faught\n",
      "13 the\n",
      "14 alot\n",
      "15 fights\n",
      "16 and\n",
      "17 apple\n",
      "18 are\n",
      "19 favorite\n",
      "20 fruits\n",
      "21 mango\n",
      "22 my\n",
      "23 hate\n",
      "24 i\n",
      "25 papaya\n",
      "26 pumpkin\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "print(dictionary)\n",
    "print(dictionary.token2id['she'])\n",
    "print(\"Number of words in dictionary:\",len(dictionary))\n",
    "for i in range(len(dictionary)):\n",
    "    print(i, dictionary[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)], [(0, 1), (4, 1), (6, 1), (7, 1), (8, 1), (9, 1)], [(7, 1), (10, 1), (11, 1), (12, 1), (13, 1)], [(3, 1), (14, 1), (15, 1)], [(16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)], [(16, 1), (23, 1), (24, 1), (25, 1), (26, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=6, num_nnz=32)\n"
     ]
    }
   ],
   "source": [
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity index with 6 documents in 0 shards (stored under sim.txt)\n",
      "<class 'gensim.similarities.docsim.Similarity'>\n"
     ]
    }
   ],
   "source": [
    "sims = gensim.similarities.Similarity('sim.txt',tf_idf[corpus],num_features=len(dictionary))\n",
    "print(sims)\n",
    "print(type(sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['simon', 'is', 'afraid', 'of', 'interview']\n",
      "[(9, 1)]\n",
      "[(9, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "query_doc = [w.lower() for w in word_tokenize(\"Simon is afraid of interview\")]\n",
    "print(query_doc)\n",
    "query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "print(query_doc_bow)\n",
    "query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "print(query_doc_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.49219605,  0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims[query_doc_tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
